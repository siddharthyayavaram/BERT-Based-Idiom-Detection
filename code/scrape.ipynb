{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(input_str):\n",
    "    formatted_str = input_str.replace('\\uFEFF', '').replace('\\u00A0', ' ').replace(\"&nbsp;\", \" \").replace(\" \", \"-\").replace(\"’\", \"\").lower()\n",
    "    return f\"{formatted_str}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face-to-face/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_input(\"face to face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.theidioms.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do(x,c):\n",
    "    for i in c:\n",
    "        idiom = i.h5.text \n",
    "        if \"zoom\" in idiom:\n",
    "            break\n",
    "        current_list = [idiom]\n",
    "        print(idiom)\n",
    "        # print(url1 + format_input(idiom))\n",
    "\n",
    "        response = requests.get(url1 + format_input(idiom))\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        c = soup.find_all('ol')\n",
    "\n",
    "        if c[1]=='<ol class=\"mpi\"><li title=\"61 Thoughts on the devil is beating his wife\"><a href=\"https://www.theidioms.com/the-devil-is-beating-his-wife/\">the devil is beating his wife</a> <span class=\"icn\">(61)</span></li><li title=\"19 Thoughts on raining cats and dogs\"><a href=\"https://www.theidioms.com/rain-cats-and-dogs/\">raining cats and dogs</a> <span class=\"icn\">(19)</span></li><li title=\"17 Thoughts on break a leg\"><a href=\"https://www.theidioms.com/break-a-leg/\">break a leg</a> <span class=\"icn\">(17)</span></li><li title=\"15 Thoughts on catch-22\"><a href=\"https://www.theidioms.com/catch-22/\">catch-22</a> <span class=\"icn\">(15)</span></li><li title=\"12 Thoughts on apple of discord\"><a href=\"https://www.theidioms.com/apple-of-discord/\">apple of discord</a> <span class=\"icn\">(12)</span></li><li title=\"12 Thoughts on a bed of roses\"><a href=\"https://www.theidioms.com/bed-of-roses/\">a bed of roses</a> <span class=\"icn\">(12)</span></li><li title=\"11 Thoughts on home is where the heart is\"><a href=\"https://www.theidioms.com/home-is-where-the-heart-is/\">home is where the heart is</a> <span class=\"icn\">(11)</span></li></ol>':\n",
    "            c = soup.find_all('ul')\n",
    "\n",
    "            for z in c[2]:\n",
    "                current_list.append(z.text.replace('\\xa0', ' '))\n",
    "\n",
    "        else:\n",
    "            for z in c[1]:\n",
    "                current_list.append(z.text.replace('\\xa0', ' '))\n",
    "\n",
    "        x.append(current_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theidioms.com/list/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "c=soup.find_all('article',class_='idiom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poke the bear\n",
      "beauty is only skin deep\n",
      "rub off\n",
      "blow off steam\n",
      "a shot in the dark\n",
      "throw in the towel\n",
      "let the cat out of the bag\n",
      "fish rots from the head down\n",
      "grit one’s teeth\n",
      "drop dead\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "do(x,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a shot in the dark',\n",
       " 'It’s hard to tell the time without a clock, but I’ll take a shot in the dark and say it’s past midnight.',\n",
       " 'I don’t have the map, but I’ll take a shot in the dark and try to find the restaurant on my own.',\n",
       " 'Submitting my story to the competition is a bit of a shot in the dark, but who knows? Maybe they’ll like it.',\n",
       " 'Driving on that narrow road in the fog felt like taking a shot in the dark; I could barely see anything.',\n",
       " 'I can’t remember where I left my glasses, so I’ll take a shot in the dark and check the kitchen.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theidioms.com/list/page/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,166):     # 166\n",
    "    print(i)\n",
    "    response = requests.get(url+str(i)+'/')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    c=soup.find_all('article',class_='idiom')\n",
    "    do(x,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1632"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [item for item in x if item[1] != 'the devil is beating his wife (61)' and item[1]!='the devil is beating his wife (62)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to idioms.txt\n",
    "with open('idioms.txt', 'w', encoding='utf-8') as idioms_file:\n",
    "    for sublist in y:\n",
    "        idioms_file.write(sublist[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    for j in range(len(y[i])):\n",
    "        y[i][j] = y[i][j].replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "for i in y:\n",
    "    ctr+= len(i[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10297"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to sentences.txt\n",
    "with open('sentences_new.txt', 'w', encoding='utf-8') as sentences_file:\n",
    "    for sublist in y:\n",
    "        sentences_file.write('\\n'.join(sublist[1:]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique lines: 10295\n"
     ]
    }
   ],
   "source": [
    "def count_unique_lines(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r',encoding='utf-8') as file:\n",
    "            # Read lines from the file\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Count the number of unique lines\n",
    "            unique_lines = set(lines)\n",
    "            num_unique_lines = len(unique_lines)\n",
    "\n",
    "            print(f\"Number of unique lines: {num_unique_lines}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Replace 'your_file.txt' with the actual path to your text file\n",
    "count_unique_lines('sentences_new.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bottom line',\n",
       " 'When the profit comes down, the bottom line is that this investment isn’t worth the risk.',\n",
       " 'The bottom line is that we need to cut costs in order to remain competitive.',\n",
       " 'At the end of everything, the bottom line is that I just want to be happy with my decision.',\n",
       " 'We can debate it all we want, but the bottom line is that this is what needs to be done.',\n",
       " 'The bottom line is that time is running out, and we need to act now.',\n",
       " 'The bottom line is that pregnant women who smoke run a higher risk of harming their health.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    print(('\\n'.join(i[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carry out',\n",
       " 'The American scientist wanted to carry out several experiments before announcing the sending of humans to Mars.',\n",
       " 'The boss carried out his orders.',\n",
       " 'She carried out her logic flawlessly.',\n",
       " 'I carried out the project according to schedule.',\n",
       " 'We must carry out our duties promptly.',\n",
       " 'Emma carried out her promise to Noah.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the list to a file using pickle\n",
    "with open('y_list.pkl', 'wb') as file:\n",
    "    pickle.dump(y, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list to a file using pickle\n",
    "with open('y_list.pkl', 'rb') as file:\n",
    "    y = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauty is only skin deep',\n",
       " 'Jacob learned the hard way that a charming smile doesn’t guarantee a good heart—beauty is only skin-deep.',\n",
       " 'She may be stunning, but remember, beauty is only skin deep; character lasts a lifetime.',\n",
       " 'Don’t be fooled by appearances; beauty is only skin-deep, and true kindness runs much deeper.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def lemmatize(word):\n",
    "    return nlp(word)[0].lemma_\n",
    "\n",
    "def tag_consecutive_lemmatized(sentence, phrase):\n",
    "    sentence_words = [lemmatize(word.text) for word in nlp(sentence)]\n",
    "    phrase_words = [lemmatize(word.text) for word in nlp(phrase)]\n",
    "\n",
    "    tagged_list = [0] * len(sentence_words)\n",
    "    \n",
    "    for i in range(len(sentence_words) - len(phrase_words) + 1):\n",
    "        if sentence_words[i:i+len(phrase_words)] == phrase_words:\n",
    "            for j in range(i, i+len(phrase_words)):\n",
    "                tagged_list[j] = 1\n",
    "\n",
    "    return tagged_list\n",
    "\n",
    "# Example usage:\n",
    "sentence_input = \"\"\n",
    "phrase_input = \"\"\n",
    "\n",
    "result = tag_consecutive_lemmatized(sentence_input, phrase_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    idiom = i[0]\n",
    "    sentence = i[1]\n",
    "    temp = tag_consecutive_lemmatized(sentence, idiom)\n",
    "    x.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result to a text file\n",
    "file_path = \"the_idioms_1.txt\"\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    # Iterate through each list in the main list (x)\n",
    "    for row in x:\n",
    "        # Convert each integer to a string and join them with spaces\n",
    "        row_str = ' '.join(map(str, row))\n",
    "        \n",
    "        # Write the row string to the file\n",
    "        file.write(row_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result to a text file\n",
    "file_path = \"the_idioms_sentences.txt\"\n",
    "\n",
    "with open(file_path, 'w', encoding = 'utf-8') as file:\n",
    "    # Iterate through each list in the main list (x)\n",
    "    for row in y:\n",
    "        # Convert each integer to a string and join them with spaces\n",
    "        # row_str = ' '.join(row[1])\n",
    "        \n",
    "        # Write the row string to the file\n",
    "        file.write(row[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_phrase(sentence, phrase_to_label):\n",
    "    # Process the input sentence and phrase\n",
    "    doc = nlp(sentence)\n",
    "    phrase_tokens = nlp(phrase_to_label)\n",
    "\n",
    "    # Lemmatize the tokens in the phrase and sentence\n",
    "    phrase_lemmas = [token.lemma_ for token in phrase_tokens]\n",
    "    sentence_lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "    # Find positions of continuous matches for a similar phrase in the sentence\n",
    "    result = [0] * len(doc)\n",
    "    phrase_length = len(phrase_lemmas)\n",
    "    for i in range(len(doc) - phrase_length + 1):\n",
    "        current_sequence = sentence_lemmas[i:i + phrase_length]\n",
    "        similarity = SequenceMatcher(None, phrase_lemmas, current_sequence).ratio()\n",
    "        if similarity > 0.90:  # Adjust this threshold based on your requirements\n",
    "            result[i:i + phrase_length] = [1] * phrase_length\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"He took a fresh cigarette offered by somebody else, lit it and then blew the smoke in Harry's face.\"\n",
    "phrase = \"blow smoke\"\n",
    "\n",
    "# sentence = \"My mother would always keep her hair on when she would argue with my father.\"\n",
    "\n",
    "result_list = similar_phrase(sentence, phrase)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def label_phrase(sentence, phrase_to_label):\n",
    "    # Process the input sentence and phrase\n",
    "    doc = nlp(sentence)\n",
    "    phrase_tokens = nlp(phrase_to_label)\n",
    "\n",
    "    # Find positions of continuous matches for the phrase in the sentence\n",
    "    result = [0] * len(doc)\n",
    "    phrase_length = len(phrase_tokens)\n",
    "    for i in range(len(doc) - phrase_length + 1):\n",
    "        if all(doc[i + j].text == phrase_tokens[j].text for j in range(phrase_length)):\n",
    "            result[i:i + phrase_length] = [1] * phrase_length\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"He took a fresh cigarette offered by somebody else, lit it and then blew the smoke in Harry's face.\"\n",
    "phrase = \"blow smoke\"\n",
    "\n",
    "result_list = label_phrase(sentence, phrase)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def label_phrase_static(sentence, phrase_to_label):\n",
    "\n",
    "    # Process the input sentence and phrase\n",
    "    doc = nlp(sentence)\n",
    "    phrase_tokens = nlp(phrase_to_label)\n",
    "\n",
    "    # Find positions of continuous matches for the idiom in the sentence\n",
    "    result = [0] * len(doc)\n",
    "    phrase_length = len(phrase_tokens)\n",
    "    for i in range(len(doc) - phrase_length + 1):\n",
    "        if [token.text for token in doc[i:i + phrase_length]] == [token.text for token in phrase_tokens]:\n",
    "            result[i:i + phrase_length] = [1] * phrase_length\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "sentence = \"The general kept his hair on during the meeting this time.\"\n",
    "phrase = \"keep his hair on\"\n",
    "\n",
    "result_list = label_phrase_static(sentence, phrase)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files for writing\n",
    "with open(\"idiom_tags_static.txt\", \"w\", encoding=\"utf-8\") as tags_file:\n",
    "    # Writing to sentences.txt\n",
    "    with open('sentences_static.txt', 'w', encoding='utf-8') as sentences_file:\n",
    "        for k in y:\n",
    "            idiom = k[0]\n",
    "            sentences = k[1:]\n",
    "            for sentence in sentences:\n",
    "                sentence = sentence[:-1]\n",
    "                labels = similar_phrase(sentence, idiom)\n",
    "                # Write tags to file\n",
    "                if sum(labels)>0:\n",
    "                    tags_file.write(\" \".join(map(str, labels)) + \"\\n\")\n",
    "                    sentences_file.write(sentence + '\\n')\n",
    "\n",
    "# Close the file\n",
    "tags_file.close()\n",
    "sentences_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criticize',\n",
       " 'the',\n",
       " 'boss',\n",
       " '’s',\n",
       " 'decision',\n",
       " 'be',\n",
       " 'a',\n",
       " 'sure',\n",
       " 'way',\n",
       " 'to',\n",
       " 'poke',\n",
       " 'the',\n",
       " 'bear',\n",
       " 'at',\n",
       " 'work',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_lemmatize('Criticizing the boss’s decisions is a sure way to poke the bear at work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = y[10][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The speech was an absolute shot in the arm for the crew members aboard the ship.',\n",
       " 'A compliment from the boss is always a shot in the arm.',\n",
       " 'Getting the scholarship was the shot in the arm she needed to continue her studies.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idiom = y[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shot in the arm'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idiom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
